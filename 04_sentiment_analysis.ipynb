{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    "\n",
    "- 단어 추출(토크나이저 재구성)\n",
    "- 사전 만들기\n",
    "- 문서 - 단어 - 벡터화(매트릭스 만들기)\n",
    "- 시기 별(1개월 단위로) \"박근혜\", \"대통령\", \"당선인\" 등 박근혜 전 대통령을 지칭하는 키워드와 유사어 추출\n",
    "\n",
    "- 워드클라우드로 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expressive-type.csv       polarity.csv              subjectivity-type.csv\n",
      "intensity.csv             readme.txt\n",
      "nested-order.csv          subjectivity-polarity.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ./lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2017.03.06</td>\n",
       "      <td>[사설] 운명의 일주일, '탄핵' '기각' 이후가 더 중요하다</td>\n",
       "      <td>이르면 이번 주 후반 박근혜 대통령 탄핵 심판 사건에 대한 헌재 결정이 나올 가능성...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>2017.03.07</td>\n",
       "      <td>[사설] 중국 땅인지 착각게 한 롯데 앞 촛불 시위대</td>\n",
       "      <td>지난 4일 밤 광주 롯데백화점 앞 촛불 시위 사진은 눈을 의심케 했다. 수백 명이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>2017.03.07</td>\n",
       "      <td>[사설] 특검, '최순실 국정농단'의 本流 꿰뚫은 수사였나</td>\n",
       "      <td>박영수 특검팀이 6일 수사 결과를 발표했다. 그러나 평가는 엇갈린다. 구속기소된 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2017.03.09</td>\n",
       "      <td>[사설] 10일 탄핵 심판 선고, 모두 自重하고 또 自制하자</td>\n",
       "      <td>박근혜 대통령 탄핵 심판 선고 기일이 10일로 확정됐다. 헌재 재판관 8명이 8일 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>2017.03.10</td>\n",
       "      <td>[사설] 오늘 시험대 오르는 대한민국, '역사적 승복'으로 위기 끝내자</td>\n",
       "      <td>헌법재판소가 오늘 11시 박근혜 대통령 탄핵심판 사건을 선고한다. 작년 10월 5일...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                    title  \\\n",
       "1017  2017.03.06       [사설] 운명의 일주일, '탄핵' '기각' 이후가 더 중요하다   \n",
       "1018  2017.03.07            [사설] 중국 땅인지 착각게 한 롯데 앞 촛불 시위대   \n",
       "1019  2017.03.07         [사설] 특검, '최순실 국정농단'의 本流 꿰뚫은 수사였나   \n",
       "1020  2017.03.09        [사설] 10일 탄핵 심판 선고, 모두 自重하고 또 自制하자   \n",
       "1021  2017.03.10  [사설] 오늘 시험대 오르는 대한민국, '역사적 승복'으로 위기 끝내자   \n",
       "\n",
       "                                                   body  \n",
       "1017  이르면 이번 주 후반 박근혜 대통령 탄핵 심판 사건에 대한 헌재 결정이 나올 가능성...  \n",
       "1018  지난 4일 밤 광주 롯데백화점 앞 촛불 시위 사진은 눈을 의심케 했다. 수백 명이 ...  \n",
       "1019  박영수 특검팀이 6일 수사 결과를 발표했다. 그러나 평가는 엇갈린다. 구속기소된 이...  \n",
       "1020  박근혜 대통령 탄핵 심판 선고 기일이 10일로 확정됐다. 헌재 재판관 8명이 8일 ...  \n",
       "1021  헌법재판소가 오늘 11시 박근혜 대통령 탄핵심판 사건을 선고한다. 작년 10월 5일...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = pd.read_pickle('cs_whole.pkl')\n",
    "data_raw.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erase \\n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"19일 실시된 대통령선거에서 새누리당 박근혜 후보가 투표자 3072만명 중 51% 남짓 1600만표가량을 얻어 18대 대통령에 당선됐다. 민주통합당 문재인 후보는 48% 남짓 1500만표가량을 얻었다. 1987년 직선제 개헌 이후 득표율 50%를 넘긴 대통령은 이번이 처음이다. 70%를 약간 넘을 것으로 예상했던 투표율은 75.8%까지 올랐다. 대한민국 건국 이후 첫 여성 대통령이 탄생했다. 박 후보의 당선으로 투표율이 높으면 야당이 유리하다는 속설(俗說)도 깨졌다.\\n경쟁자 지지 국민의 박탈감 헤아려야\\n\\n정권 재창출보다 정권 교체를 바라는 여론이 더 높은 가운데 치러진 이번 대선은 박 후보에게 버거운 선거였다. 선거 초반 한동안 유지되던 박근혜 대세론은 무소속 안철수 후보 등장으로 몇 차례 크게 흔들렸다. 박 후보는 박근혜·문재인·안철수 3자 가상(假想) 대결에선 늘 1위를 지켰으나 야당 단일 후보에겐 밀리는 결과가 몇 번이나 나타났다. 안 후보 사퇴 이후 박 후보에게 10%포인트 이상 뒤지던 문 후보의 지지율이 꾸준히 올라가 선거 이틀 전에는 뒤집히기도 했다.\\n\\n이 순간 박 당선인에게 가장 절실한 자세는 자신을 지지한 1600만 국민과 함께 자신의 경쟁자에게 표를 던진 1500만 국민의 마음을 정확히 읽고 그들을 진정으로 끌어안는 것이다. 이명박 정부 5년 동안 우리나라는 미국발(發) 금융위기·유럽발 재정위기 속에서도 세계 각국 가운데 거시(巨視)경제지표가 가장 빨리 호전되고 한 사회의 소득 불평등 정도를 가리키는 지니계수도 노무현 정부 동안 계속 악화하다 2009년 0.320에서 2011년 0.313으로 개선됐다. 그럼에도 국민은 이런 지표 개선과 관계없이 어쩌면 오히려 그것 때문에 더 큰 경제적 고통과 상대적 박탈감을 느껴왔다. 대기업의 경기가 좋아지면, 고소득자의 소득이 높아지면, 그 효과가 형편이 어려운 사람들에게도 퍼져간다는 이른바 '낙수(落水)효과'는 현실과 거리가 먼 것으로 드러났다.\\n\\nDB손해보험 다이렉트 바로가기\\n젊은이들은 대학을 졸업해도 번\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.body[0][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"19일 실시된 대통령선거에서 새누리당 박근혜 후보가 투표자 3072만명 중 51% 남짓 1600만표가량을 얻어 18대 대통령에 당선됐다. 민주통합당 문재인 후보는 48% 남짓 1500만표가량을 얻었다. 1987년 직선제 개헌 이후 득표율 50%를 넘긴 대통령은 이번이 처음이다. 70%를 약간 넘을 것으로 예상했던 투표율은 75.8%까지 올랐다. 대한민국 건국 이후 첫 여성 대통령이 탄생했다. 박 후보의 당선으로 투표율이 높으면 야당이 유리하다는 속설(俗說)도 깨졌다. 경쟁자 지지 국민의 박탈감 헤아려야  정권 재창출보다 정권 교체를 바라는 여론이 더 높은 가운데 치러진 이번 대선은 박 후보에게 버거운 선거였다. 선거 초반 한동안 유지되던 박근혜 대세론은 무소속 안철수 후보 등장으로 몇 차례 크게 흔들렸다. 박 후보는 박근혜·문재인·안철수 3자 가상(假想) 대결에선 늘 1위를 지켰으나 야당 단일 후보에겐 밀리는 결과가 몇 번이나 나타났다. 안 후보 사퇴 이후 박 후보에게 10%포인트 이상 뒤지던 문 후보의 지지율이 꾸준히 올라가 선거 이틀 전에는 뒤집히기도 했다.  이 순간 박 당선인에게 가장 절실한 자세는 자신을 지지한 1600만 국민과 함께 자신의 경쟁자에게 표를 던진 1500만 국민의 마음을 정확히 읽고 그들을 진정으로 끌어안는 것이다. 이명박 정부 5년 동안 우리나라는 미국발(發) 금융위기·유럽발 재정위기 속에서도 세계 각국 가운데 거시(巨視)경제지표가 가장 빨리 호전되고 한 사회의 소득 불평등 정도를 가리키는 지니계수도 노무현 정부 동안 계속 악화하다 2009년 0.320에서 2011년 0.313으로 개선됐다. 그럼에도 국민은 이런 지표 개선과 관계없이 어쩌면 오히려 그것 때문에 더 큰 경제적 고통과 상대적 박탈감을 느껴왔다. 대기업의 경기가 좋아지면, 고소득자의 소득이 높아지면, 그 효과가 형편이 어려운 사람들에게도 퍼져간다는 이른바 '낙수(落水)효과'는 현실과 거리가 먼 것으로 드러났다.  DB손해보험 다이렉트 바로가기 젊은이들은 대학을 졸업해도 번\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.body = data_raw.body.apply(lambda x : re.sub(\"\\n\", \" \", x) if re.findall(\"\\n\", x) else x)\n",
    "data_raw.body[0][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"19일 실시된 대통령선거에서 새누리당 박근혜 후보가 투표자 3072만명 중 51% 남짓 1600만표가량을 얻어 18대 대통령에 당선됐다. 민주통합당 문재인 후보는 48% 남짓 1500만표가량을 얻었다. 1987년 직선제 개헌 이후 득표율 50%를 넘긴 대통령은 이번이 처음이다. 70%를 약간 넘을 것으로 예상했던 투표율은 75.8%까지 올랐다. 대한민국 건국 이후 첫 여성 대통령이 탄생했다. 박 후보의 당선으로 투표율이 높으면 야당이 유리하다는 속설(俗說)도 깨졌다. 경쟁자 지지 국민의 박탈감 헤아려야  정권 재창출보다 정권 교체를 바라는 여론이 더 높은 가운데 치러진 이번 대선은 박 후보에게 버거운 선거였다. 선거 초반 한동안 유지되던 박근혜 대세론은 무소속 안철수 후보 등장으로 몇 차례 크게 흔들렸다. 박 후보는 박근혜·문재인·안철수 3자 가상(假想) 대결에선 늘 1위를 지켰으나 야당 단일 후보에겐 밀리는 결과가 몇 번이나 나타났다. 안 후보 사퇴 이후 박 후보에게 10%포인트 이상 뒤지던 문 후보의 지지율이 꾸준히 올라가 선거 이틀 전에는 뒤집히기도 했다.  이 순간 박 당선인에게 가장 절실한 자세는 자신을 지지한 1600만 국민과 함께 자신의 경쟁자에게 표를 던진 1500만 국민의 마음을 정확히 읽고 그들을 진정으로 끌어안는 것이다. 이명박 정부 5년 동안 우리나라는 미국발(發) 금융위기·유럽발 재정위기 속에서도 세계 각국 가운데 거시(巨視)경제지표가 가장 빨리 호전되고 한 사회의 소득 불평등 정도를 가리키는 지니계수도 노무현 정부 동안 계속 악화하다 2009년 0.320에서 2011년 0.313으로 개선됐다. 그럼에도 국민은 이런 지표 개선과 관계없이 어쩌면 오히려 그것 때문에 더 큰 경제적 고통과 상대적 박탈감을 느껴왔다. 대기업의 경기가 좋아지면, 고소득자의 소득이 높아지면, 그 효과가 형편이 어려운 사람들에게도 퍼져간다는 이른바 '낙수(落水)효과'는 현실과 거리가 먼 것으로 드러났다.  DB손해보험 다이렉트 바로가기 젊은이들은 대학을 졸업해도 번\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = data_raw.body.values\n",
    "corpus = list(corpus)\n",
    "corpus[0][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.238 Gb\n"
     ]
    }
   ],
   "source": [
    "from soynlp.word import WordExtractor\n",
    "\n",
    "word_extractor = WordExtractor(\n",
    "    max_left_length=10,\n",
    "    max_right_length=6,\n",
    "    min_frequency=5\n",
    ")\n",
    "\n",
    "word_extractor.train(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all cohesion probabilities was computed. # words = 27258\n",
      "all branching entropies was computed # words = 42263\n",
      "all accessor variety was computed # words = 42263\n"
     ]
    }
   ],
   "source": [
    "scores = word_extractor.word_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scores(cohesion_forward=0.9183683615125757, cohesion_backward=0.24505110018405926, left_branching_entropy=2.3429356954455187, right_branching_entropy=0.90776970980902, left_accessor_variety=53, right_accessor_variety=13, leftside_frequency=1131, rightside_frequency=72)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['박근혜']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.tokenizer import LTokenizer, MaxScoreTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def make_dataset(corpus):\n",
    "\n",
    "    # scores dict로 cohesion scores, ltokenizer 만들기\n",
    "    cohesion_scores = {word:score.cohesion_forward for word, score in scores.items()}\n",
    "    ltokenizer = LTokenizer(scores=cohesion_scores)\n",
    "\n",
    "    def l_tokenizer(word):\n",
    "        return ltokenizer.tokenize(word, remove_r=True)\n",
    "\n",
    "    # ltokenizer를 활용해서 벡터라이저 만들기\n",
    "    vectorizer = CountVectorizer(\n",
    "        tokenizer=l_tokenizer,\n",
    "    )\n",
    "\n",
    "    # x 만들기\n",
    "    x = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    # vocab2int, int2vocab 만들기\n",
    "    vocab2int = vectorizer.vocabulary_\n",
    "    int2vocab = [\n",
    "        word for word, index in sorted(vocab2int.items(), key=lambda x:x[1])\n",
    "    ]\n",
    "    \n",
    "    return x, vocab2int, int2vocab\n",
    "\n",
    "x, vocab2int, int2vocab = make_dataset(corpus)\n",
    "\n",
    "def word2int(word):\n",
    "    return vocab2int.get(word, -1)\n",
    "\n",
    "def int2word(idx):\n",
    "    if 0 <= idx < len(int2vocab):\n",
    "        return int2vocab[idx]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_sparse.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,022 중 965 문서가 \"박근혜\" 라는 단어를 가지고 있습니다.\n",
      "1,022 중 907 문서가 \"대통령\" 라는 단어를 가지고 있습니다.\n",
      "1,022 중  93 문서가 \"당선인\" 라는 단어를 가지고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "keyword_list = [\"박근혜\", \"대통령\", \"당선인\"]\n",
    "\n",
    "for word in keyword_list:\n",
    "\n",
    "    word_idx = word2int(word)\n",
    "    positive_document = x[:, word_idx].nonzero()[0]\n",
    "\n",
    "    print('{:3,} 중 {:3,} 문서가 \"{}\" 라는 단어를 가지고 있습니다.'.format(x.shape[0], len(positive_document), word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,022 중 965 문서가 \"박근혜\" 라는 단어를 가지고 있습니다.\n",
      "Counter({1: 965, -1: 57})\n"
     ]
    }
   ],
   "source": [
    "word = \"박근혜\"\n",
    "word_idx = word2int(word)\n",
    "positive_document = x[:, word_idx].nonzero()[0]\n",
    "\n",
    "print('{:3,} 중 {:3,} 문서가 \"{}\" 라는 단어를 가지고 있습니다.'.format(x.shape[0], len(positive_document), word))\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "y = [1 if i in positive_document else -1 for i in range(x.shape[0])]\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(word):\n",
    "    \n",
    "    word_idx = word2int(word) # word2int 함수 필요\n",
    "    positive_document = x[:, word_idx].nonzero()[0] # x 데이터셋 필요\n",
    "    \n",
    "    def get_label(i):\n",
    "        return 1 if i in positive_document else -1\n",
    "    \n",
    "    y_train = [get_label(i) for i in range(x.shape[0])]\n",
    "    \n",
    "    (row, col) = x.nonzero()\n",
    "    data = x.data\n",
    "    \n",
    "    row_ = []\n",
    "    col_ = []\n",
    "    data_ = []\n",
    "    \n",
    "    for r, c, d in zip(row, col, data):\n",
    "        if c == word_idx:\n",
    "            continue\n",
    "        row_.append(r)\n",
    "        col_.append(c)\n",
    "        data_.append(d)\n",
    "        \n",
    "    from scipy.sparse import csr_matrix\n",
    "    x_train = csr_matrix((data_, (row_, col_)))\n",
    "    \n",
    "    return x_train, y_train\n",
    "\n",
    "x_train, y_train = get_train_data('박근혜')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-273-eff592d08a92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogistic_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlogistic_l1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlasso_keyword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    870\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[1;32m    871\u001b[0m                              \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mclass_weight_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_l1 = LogisticRegression(penalty='l1', C=10)\n",
    "logistic_l1.fit(x_train, y_train)\n",
    "\n",
    "def lasso_keyword(word, C=20, topk=20):\n",
    "    if not (word in vocab2int):\n",
    "        return []\n",
    "    \n",
    "    x_train, y_train = get_train_data(word)\n",
    "    logistic_l1 = LogisticRegression(penalty='l1', C=C)\n",
    "    logistic_l1.fit(x_train, y_train)\n",
    "    \n",
    "    idx_coef = enumerate(logistic_l1.coef_.reshape(-1))\n",
    "    sorted_coefficients = sorted(idx_coef, key=lambda x:-x[1])\n",
    "    \n",
    "    # filtering keyword\n",
    "    keywords = [word_idx for word_idx, coef in sorted_coefficients[:topk] \n",
    "                if coef > 0.001]\n",
    "    \n",
    "    # decode idx to str\n",
    "    keywords = [int2word(word_idx) for word_idx in keywords]\n",
    "    return keywords\n",
    "\n",
    "print(lasso_keyword('박근혜'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "있어\n",
      "당선인\n",
      "계엄\n",
      "한·미\n",
      "촛불\n",
      "요구\n",
      "도발\n",
      "관계\n",
      "허위\n",
      "한다.\n"
     ]
    }
   ],
   "source": [
    "# idx_coef = enumerate(logistic_l1.coef_.reshape(-1))\n",
    "# sorted_coefficients = sorted(idx_coef, key=lambda x:-x[1])\n",
    "\n",
    "# for word_idx, coef in sorted_coefficients[:10]:\n",
    "#     if coef < 0.001: break\n",
    "#     print(int2word(word_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 노트\n",
    "\n",
    "1. customized_tokenizer가 명사, 용언만 가져오지 않기 때문에 \"있어\", \"한다.\"처럼 불필요한 단어가 상위에 등장한다.\n",
    "> 사설 분석에 적합한 토크나이저가 필요하다.\n",
    "\n",
    "2. 시기 별 키워드 분석을 위해서는 월 단위로 기사 분류.\n",
    "3. 월(혹은 분기) 단위로 워드클라우드 구현.\n",
    "4. 전체 사설 데이터를 활용하는게 더 나을 수 있다.\n",
    "5. 옛날 신문 같은 경우에는 한자를 한글로 변환해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012.12</td>\n",
       "      <td>[사설] 박근혜 당선인, 겸허하게 온 국민 껴안는 걸로 시작하라</td>\n",
       "      <td>19일 실시된 대통령선거에서 새누리당 박근혜 후보가 투표자 3072만명 중 51% ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012.12</td>\n",
       "      <td>[사설] 선거 여론조사, '公表 금지 기간' 없애거나 더 단축을</td>\n",
       "      <td>국민은 여론조사 공표가 금지된 지난 13일부터 18일까지 6일 동안 여론 흐름을 전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012.12</td>\n",
       "      <td>[사설] 한국 진보 左派, 進化하지 않으면 몰락한다</td>\n",
       "      <td>민주당 문재인 후보는 범(汎)야권 후보를 완벽하게 단일화하고 투표율이 자신들이 야당...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012.12</td>\n",
       "      <td>[사설] 政權 인수, 소리 내지 말고 실무적으로 하라</td>\n",
       "      <td>곧 박근혜대통령직인수위원회가 발족한다. 역대 대통령직인수위에 대한 국민 기억은 그다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012.12</td>\n",
       "      <td>[사설] '5060世代 지혜' 못지않게 '2030 氣 살리기'도 중요하다</td>\n",
       "      <td>19일의 대선에서 50대(代) 투표율이 89.9%였던 것으로 방송사 출구 조사에서 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date                                     title  \\\n",
       "0  2012.12       [사설] 박근혜 당선인, 겸허하게 온 국민 껴안는 걸로 시작하라   \n",
       "1  2012.12       [사설] 선거 여론조사, '公表 금지 기간' 없애거나 더 단축을   \n",
       "2  2012.12              [사설] 한국 진보 左派, 進化하지 않으면 몰락한다   \n",
       "3  2012.12             [사설] 政權 인수, 소리 내지 말고 실무적으로 하라   \n",
       "4  2012.12  [사설] '5060世代 지혜' 못지않게 '2030 氣 살리기'도 중요하다   \n",
       "\n",
       "                                                body  \n",
       "0  19일 실시된 대통령선거에서 새누리당 박근혜 후보가 투표자 3072만명 중 51% ...  \n",
       "1  국민은 여론조사 공표가 금지된 지난 13일부터 18일까지 6일 동안 여론 흐름을 전...  \n",
       "2  민주당 문재인 후보는 범(汎)야권 후보를 완벽하게 단일화하고 투표율이 자신들이 야당...  \n",
       "3  곧 박근혜대통령직인수위원회가 발족한다. 역대 대통령직인수위에 대한 국민 기억은 그다...  \n",
       "4  19일의 대선에서 50대(代) 투표율이 89.9%였던 것으로 방송사 출구 조사에서 ...  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_revise = data_raw.copy()\n",
    "data_revise.date = data_revise.date.apply(lambda x : x[:7])\n",
    "data_revise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기간 별 텍스트 데이터 취합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2012.12', '2013.01', '2013.02', '2013.03', '2013.04', '2013.05',\n",
       "       '2013.06', '2013.07', '2013.08', '2013.09', '2013.10', '2013.11',\n",
       "       '2013.12', '2014.01', '2014.02', '2014.03', '2014.04', '2014.05',\n",
       "       '2014.06', '2014.07', '2014.08', '2014.09', '2014.10', '2014.11',\n",
       "       '2014.12', '2015.01', '2015.02', '2015.03', '2015.04', '2015.05',\n",
       "       '2015.06', '2015.07', '2015.08', '2015.09', '2015.10', '2015.11',\n",
       "       '2015.12', '2016.01', '2016.02', '2016.03', '2016.04', '2016.05',\n",
       "       '2016.06', '2016.07', '2016.08', '2016.09', '2016.10', '2016.11',\n",
       "       '2016.12', '2017.01', '2017.02', '2017.03', ': 2016.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month = np.unique(data_revise.date)\n",
    "month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, title, body]\n",
       "Index: []"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merged = pd.DataFrame(columns=['date', 'title', 'body'])\n",
    "data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012.12</td>\n",
       "      <td>[사설] 박근혜 당선인, 겸허하게 온 국민 껴안는 걸로 시작하라[사설] 선거 여론조...</td>\n",
       "      <td>19일 실시된 대통령선거에서 새누리당 박근혜 후보가 투표자 3072만명 중 51% ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013.01</td>\n",
       "      <td>[사설] \"남북 대결 상태 해소\" 북한 하기에 달려[사설] 극빈층 3% 진료비, 상...</td>\n",
       "      <td>김정은 북한 노동당 제1비서는 1일 북한 매체를 통해 중계된 육성 신년사에서 \"나라...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013.02</td>\n",
       "      <td>[사설] 청문회 통과할 후보 먼저 찾고 제도 개선은 추후로[사설] 朴 당선인에게 속...</td>\n",
       "      <td>박근혜 대통령 당선인은 1월 31일 인사청문회에 대해 \"공직자의 신상에 대한 문제는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013.03</td>\n",
       "      <td>[사설] 與黨 지도부가 움직여야 할 때다[사설] 청문회장의 '5·16 愚問愚答' 보...</td>\n",
       "      <td>새누리당 황우여 대표와 이한구 원내대표는 2월 28일 최고위원 회의 모두 발언에서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013.04</td>\n",
       "      <td>[사설] 세금 야박하게 긁어낸다고 福祉 비용 댈 수 있을까[사설] 핵 끌어안고 경제...</td>\n",
       "      <td>정부가 올해 예산 편성을 하면서 교통범칙금 징수 목표 액수를 작년보다 12%(900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013.05</td>\n",
       "      <td>[사설] 단발성 규제 완화론 '投資 붐' 일으킬 수 없다[사설] 긴박한 한반도 정세...</td>\n",
       "      <td>정부는 1일 열린 무역투자진흥회의에서 그동안 허가를 미루고 있던 에쓰오일·SK종합화...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013.06</td>\n",
       "      <td>[사설] 대통령 지지율을 국정 動力으로 연결하려면[사설] 고위 공무원 여성 비율 4...</td>\n",
       "      <td>4일 박근혜 대통령은 취임 100일을 맞는다. 취임 100일을 앞두고 미디어리서치가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013.07</td>\n",
       "      <td>[사설] 韓·中 관계는 새로운 시대의 門 앞에 서 있다[사설] 동북아 전환기 속 진...</td>\n",
       "      <td>박근혜 대통령이 4일간의 중국 방문을 마치고 30일 귀국했다. 박 대통령은 새 대통...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013.08</td>\n",
       "      <td>[사설] 새누리 지휘부, 정국 主導 정치력 발휘하라[사설] '송전탑 반대' 전국 확...</td>\n",
       "      <td>여야는 4일 국정원 국정조사 정상화 협상을 재개, 국정원 보고를 예정대로 듣기로 하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013.09</td>\n",
       "      <td>[사설] 與野, 정기국회 허송하고 막판 벼락치기 할 건가[사설] 기초연금 축소, 먼...</td>\n",
       "      <td>정기국회가 2일 문을 열었지만 여야는 통합진보당 이석기 의원 체포동의안 처리에 합의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013.10</td>\n",
       "      <td>[사설] 기초연금, 더 쉽고 솔직하게 국민에게 설명하라[사설] 진영 장관 누굴 위해...</td>\n",
       "      <td>박근혜 대통령은 30일 청와대 수석비서관 회의에서 \"기초연금 정부안(案)에 대해 청...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013.11</td>\n",
       "      <td>[사설] 두 차례 재·보선 5곳서 全敗한 민주당의 선택[사설] 北은 朴대통령의 남북...</td>\n",
       "      <td>민주당이 30일 경기 화성갑과 경북 포항남·울릉 등 두 곳에서 실시된 국회의원 보선...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013.12</td>\n",
       "      <td>[사설] 준비 없이 농축산 시장 열면 '쇠고기 사태' 또 올 수도[사설] 엔低 파장...</td>\n",
       "      <td>우태희 산업통상자원부 통상교섭실장은 \"우리가 12개 태평양 연안국이 추진하고 있는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014.01</td>\n",
       "      <td>[사설] 관료 기강, 잡을 땐 잡되 왜 흐트러졌는지 원인도 봐야[사설] '남북 관계...</td>\n",
       "      <td>국무총리 산하 1급 실장급 공무원 10명 전원이 최근 사직서를 냈다고 한다. 집단 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014.02</td>\n",
       "      <td>[사설] 오바마 日 가고 한국 안 오면 어떤 메시지 주겠는가[사설] 그래도 북한 아...</td>\n",
       "      <td>오는 4월로 예정된 오바마 미국 대통령의 아시아 순방 일정을 놓고 한국과 일본이 외...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014.03</td>\n",
       "      <td>[사설] \"한반도 통일은 아시아와 세계의 새 成長 동력 될 것\"[사설] 국방 개혁도...</td>\n",
       "      <td>3일 서울에서 열린 조선일보 주최 제5회 아시안리더십콘퍼런스의 주제는 '하나의 한국...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014.04</td>\n",
       "      <td>[사설] 北, NLL 포격·핵실험으로 대북 지원 제안 걷어찰 건가[사설] 野 대표에...</td>\n",
       "      <td>북한이 31일 낮 서해 북방한계선(NLL) 인근 해역에서 대규모 사격 훈련을 실시했...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014.05</td>\n",
       "      <td>[사설] 대통령·與野, 이번만은 정파 떠나 '국민 安全' 머리 맞대야[사설] 無能한...</td>\n",
       "      <td>박근혜 대통령은 그제 국무회의에서 \"과거로부터 쌓여온 잘못된 적폐(積弊)를 바로잡지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014.06</td>\n",
       "      <td>[사설] 金 안보실장, '또 軍 출신 발탁'에 대한 우려 씻어내야[사설] 완승·완패...</td>\n",
       "      <td>박근혜 대통령은 1일 신임 청와대 국가안보실장에 김관진 현 국방장관을 임명하고, 후...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014.07</td>\n",
       "      <td>[사설] 대통령의 '총리 留任' 해명, 이 정도로 충분하겠나[사설] 해직 교사 9명...</td>\n",
       "      <td>박근혜 대통령이 30일 청와대 수석비서관 회의에서 정홍원 총리를 유임시킨 이유에 대...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2014.08</td>\n",
       "      <td>[사설] 시대 변화 못 읽는 野, 이대로는 미래 없다[사설] 美·유엔, 위안부 문제...</td>\n",
       "      <td>새정치민주연합 지도부가 31일 총사퇴했다. 새정치연합은 전날 전국 15곳에서 치러진...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014.09</td>\n",
       "      <td>[사설] 최전방 사령관의 軍律 무시·만취 추태, 어쩌다 이 지경 됐나[사설] 규제 ...</td>\n",
       "      <td>신현돈 육군 1군 사령관(대장)이 2일 갑작스럽게 전역(轉役) 조치됐다. 현역 군인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2014.10</td>\n",
       "      <td>[사설] 北 실세들의 깜짝 방문, 차분하게 남북대화 이끌어야[사설] 군·국정원 人事...</td>\n",
       "      <td>남북 관계가 뜻밖의 전기(轉機)를 맞았다. 북한 권력 서열 2위로 평가되는 황병서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014.11</td>\n",
       "      <td>[사설] 애당초 海警·소방청 해체 발표가 성급했다[사설] 세월號특별법 합의, 이젠 ...</td>\n",
       "      <td>여야는 31일 소방방재청과 해양경찰청을 해체한 뒤 새로 생기는 국민안전처 산하 '중...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2014.12</td>\n",
       "      <td>[사설] 박 대통령, '정윤회 文件' 유출만 탓할 일 아니다[사설] '1兆 배당說'...</td>\n",
       "      <td>박근혜 대통령이 1일 청와대 회의에서 '정윤회 국정 개입 의혹 문서' 유출 사건에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2015.01</td>\n",
       "      <td>[사설] 분단 70년 恨 푸는 남북 정상회담을 바란다[사설] 檢 \"정윤회 문건은 허...</td>\n",
       "      <td>북한 김정은 노동당 제1비서는 1일 TV에 나와 직접 발표한 신년사를 통해 \"올해 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2015.02</td>\n",
       "      <td>[사설] 非朴 원내대표 당선은 대통령 향한 여당의 경고[사설] '국민 속였다'는 與...</td>\n",
       "      <td>2일 실시된 새누리당 원내대표 경선에서 유승민 의원이 84표를 얻어 65표에 그친 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2015.03</td>\n",
       "      <td>[사설] 현역 의원 대통령 보좌관 임명은 3權분립 위반 아닌가[사설] 한국이 처음 ...</td>\n",
       "      <td>청와대는 지난주 새누리당 주호영·윤상현·김재원 의원을 대통령 정무특보로 임명하면서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2015.04</td>\n",
       "      <td>[사설] 대통령이 제주 4·3 추념식에 참석할 수 있으려면[사설] '세월호 인양 결...</td>\n",
       "      <td>오늘 제주도 4·3 평화공원에서 지난해 3월 국가 기념일로 지정된 '4·3 희생자 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2015.05</td>\n",
       "      <td>[사설] 외교도, 경제도,개혁도 못하는 '무기력 청와대'[사설] 朴 대통령, '정치...</td>\n",
       "      <td>박근혜 대통령이 조만간 공식 일정을 재개할 예정이라 한다. 지난 보름여 동안 이 정...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2015.06</td>\n",
       "      <td>[사설] 전면전으로 번지는 黨·靑 '국회법' 갈등, 국민은 안중에도 없나[사설] 野...</td>\n",
       "      <td>박근혜 대통령이 1일 여야 합의로 국회를 통과한 국회법 개정안에 대해 \"정부로서는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2015.07</td>\n",
       "      <td>[사설] 국회법 再議 뭉개겠다는 與, 이게 올바른 집권당 자세인가[사설] 경제는 6...</td>\n",
       "      <td>정의화 국회의장은 30일 박근혜 대통령이 거부권을 행사한 '국회법 개정안'을 국회 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2015.08</td>\n",
       "      <td>[사설] 極端에서 극단으로 오가는 對日 외교[사설] 정 내정자, '의료계 대변인' ...</td>\n",
       "      <td>박근혜 대통령이 3일 일본 야당인 민주당의 오카다 가쓰야 대표를 만난 자리에서 \"과...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2015.09</td>\n",
       "      <td>[사설] 박 대통령 訪中, '美 의구심' 씻어낼 외교 전략 절실하다[사설] 밖의 시...</td>\n",
       "      <td>윤병세 외교부장관이 31일(현지 시각) 미국 알래스카주(州) 앵커리지에서 존 케리 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2015.10</td>\n",
       "      <td>[사설] 박 대통령과 김 대표, 공천권 놓고 벌써 공개 舌戰 벌일 때인가[사설] 靑...</td>\n",
       "      <td>청와대 고위 관계자가 30일 김무성 새누리당·문재인 새정치연합 대표가 내년 총선 공...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2015.11</td>\n",
       "      <td>[사설] 韓·日 정상, '新조선통신사의 和合 염원' 외면 말라[사설] 韓中日 3자회...</td>\n",
       "      <td>화합의 꿈을 안고 달린 50명의 한·일 자전거 라이더 '두 바퀴로 달리는 신(新)조...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2015.12</td>\n",
       "      <td>[사설] 박 대통령, 野·노조 지도자 만나 간절하게 호소해보라[사설] 막장 집안싸움...</td>\n",
       "      <td>박근혜 대통령은 7일 김무성 대표, 원유철 원내대표 등 여당 지도부를 만나 \"지금 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2016.01</td>\n",
       "      <td>[사설] 새로운 政治 리더십으로 나라가 활기 되찾아야 한다[사설] 잘나가는 벤처 강...</td>\n",
       "      <td>1492년 콜럼버스가 배 세 척을 이끌고 신대륙에 도달했을 당시 유럽인은 중국을 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2016.02</td>\n",
       "      <td>[사설] 제4이동통신 또 무산, 미래창조부 제대로 하는 일 뭐 있나[사설] 알맹이 ...</td>\n",
       "      <td>제4이동통신 사업자 선정이 또다시 무산됐다. 이 사업은 SK, LG, KT 등 대기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2016.03</td>\n",
       "      <td>[사설] 쪼그라드는 경제, '好況 맛' 한번 못 보고 5년 임기 끝낼 건가[사설] ...</td>\n",
       "      <td>지난해 우리나라의 1인당 국민소득이 2만7200달러를 기록, 9년째 3만달러 문턱을...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2016.04</td>\n",
       "      <td>[사설] 한·미·일 공조 강화해 中의 '북한 압박' 약속 지키게 해야[사설] 시진핑...</td>\n",
       "      <td>제4차 핵안보정상회의에 앞서 31일 미국 워싱턴DC에서 열린 한·미·일 정상회의에서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2016.05</td>\n",
       "      <td>[사설] 새 차원의 中東 大전략 나와야 할 때다[사설] 北은 우방국 이란 대통령의 ...</td>\n",
       "      <td>박근혜 대통령이 1일 이란을 방문했다. 한국 대통령으로는 1962년 국교 수교 이후...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2016.06</td>\n",
       "      <td>[사설] 20대 국회 개혁 '불체포特權 폐지' 하나에 달렸다[사설] 줄거리조차 못 ...</td>\n",
       "      <td>원혜영 더불어민주당 의원이 31일 '국회의원 불체포특권 남용 방지법'을 제출했다. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2016.07</td>\n",
       "      <td>[사설] 한국형 우주로켓 연기, 무리한 대선 公約에 무너진 '과학'[사설] 조응천 ...</td>\n",
       "      <td>국산 우주로켓을 개발 중인 한국항공우주연구원이 당초 내년 12월로 예정했던 한국형 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2016.08</td>\n",
       "      <td>[사설] 근로자 절반이 소득세 '0', 정치 포퓰리즘 결과[사설] \"禹 수석 정상 ...</td>\n",
       "      <td>국책 연구기관인 조세재정연구원이 우리나라 근로자 가운데 세금을 한 푼도 내지 않는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2016.09</td>\n",
       "      <td>[사설] 방어 무기 하나 놓고 두 달 소란, 政局 마비된 나라[사설] 나라 사방이 ...</td>\n",
       "      <td>사드(고고도 미사일 방어 체계)가 연이틀 국회를 마비시켰다. 여당이 정치 중립 위반...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2016.10</td>\n",
       "      <td>[사설] 미르·K스포츠 재단 뒤늦게 해산·통합한다는데[사설] 상식으로 납득하기 어려...</td>\n",
       "      <td>전경련은 30일 사실상 청와대가 설립했다는 의혹이 제기된 미르(용·龍)와 K스포츠 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2016.11</td>\n",
       "      <td>[사설] 최순실 출두 이어 대통령이 고백하길[사설] 박 대통령 脫黨하고 친박·비박 ...</td>\n",
       "      <td>최순실씨가 31일 검찰에 출석했다. 최씨는 \"국민 여러분, 용서해주십시오\"라고 했다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2016.12</td>\n",
       "      <td>[사설] '親朴 개헌' 불가능, 朴 대통령은 퇴진 명확히 하길[사설] 野 대통령 퇴...</td>\n",
       "      <td>박근혜 대통령이 지난 29일 자신의 임기 단축 문제를 국회에 일임하겠다고 밝혔지만 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2017.01</td>\n",
       "      <td>[사설] \"엮지 말라\" 전면 부인 나선 朴 대통령[사설] 탄핵 반대 고교생이 당한 ...</td>\n",
       "      <td>직무 정지 중인 박근혜 대통령이 1일 기자들과 신년인사회 자리에서 특검의 '삼성 합...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2017.02</td>\n",
       "      <td>[사설] 최순실, 장차관·수석 이어 大使 임명도 개입했다니[사설] 國定교과서와 質로...</td>\n",
       "      <td>최순실씨가 유재경 주(駐)미얀마 대사 임명 및 해외 공적개발원조(ODA) 사업에도 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2017.03</td>\n",
       "      <td>[사설] 역사적 탄핵 심판 첫 평의, '절대 非공개'로 헌재 보호해야[사설] 촛불·...</td>\n",
       "      <td>헌법재판소가 28일 재판관 8명 전원이 참석한 가운데 박근혜 대통령 탄핵심판 첫 평...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>: 2016.</td>\n",
       "      <td>[사설] 알맹이 빠지는 노동 개혁, 이러려면 뭐하러 그 요란 떨었나[사설] 원칙도 ...</td>\n",
       "      <td>정부와 새누리당이 국회 쟁점 법안 중 하나인 파견근로자보호법 개정안에서 뿌리 산업의...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date                                              title  \\\n",
       "0   2012.12  [사설] 박근혜 당선인, 겸허하게 온 국민 껴안는 걸로 시작하라[사설] 선거 여론조...   \n",
       "1   2013.01  [사설] \"남북 대결 상태 해소\" 북한 하기에 달려[사설] 극빈층 3% 진료비, 상...   \n",
       "2   2013.02  [사설] 청문회 통과할 후보 먼저 찾고 제도 개선은 추후로[사설] 朴 당선인에게 속...   \n",
       "3   2013.03  [사설] 與黨 지도부가 움직여야 할 때다[사설] 청문회장의 '5·16 愚問愚答' 보...   \n",
       "4   2013.04  [사설] 세금 야박하게 긁어낸다고 福祉 비용 댈 수 있을까[사설] 핵 끌어안고 경제...   \n",
       "5   2013.05  [사설] 단발성 규제 완화론 '投資 붐' 일으킬 수 없다[사설] 긴박한 한반도 정세...   \n",
       "6   2013.06  [사설] 대통령 지지율을 국정 動力으로 연결하려면[사설] 고위 공무원 여성 비율 4...   \n",
       "7   2013.07  [사설] 韓·中 관계는 새로운 시대의 門 앞에 서 있다[사설] 동북아 전환기 속 진...   \n",
       "8   2013.08  [사설] 새누리 지휘부, 정국 主導 정치력 발휘하라[사설] '송전탑 반대' 전국 확...   \n",
       "9   2013.09  [사설] 與野, 정기국회 허송하고 막판 벼락치기 할 건가[사설] 기초연금 축소, 먼...   \n",
       "10  2013.10  [사설] 기초연금, 더 쉽고 솔직하게 국민에게 설명하라[사설] 진영 장관 누굴 위해...   \n",
       "11  2013.11  [사설] 두 차례 재·보선 5곳서 全敗한 민주당의 선택[사설] 北은 朴대통령의 남북...   \n",
       "12  2013.12  [사설] 준비 없이 농축산 시장 열면 '쇠고기 사태' 또 올 수도[사설] 엔低 파장...   \n",
       "13  2014.01  [사설] 관료 기강, 잡을 땐 잡되 왜 흐트러졌는지 원인도 봐야[사설] '남북 관계...   \n",
       "14  2014.02  [사설] 오바마 日 가고 한국 안 오면 어떤 메시지 주겠는가[사설] 그래도 북한 아...   \n",
       "15  2014.03  [사설] \"한반도 통일은 아시아와 세계의 새 成長 동력 될 것\"[사설] 국방 개혁도...   \n",
       "16  2014.04  [사설] 北, NLL 포격·핵실험으로 대북 지원 제안 걷어찰 건가[사설] 野 대표에...   \n",
       "17  2014.05  [사설] 대통령·與野, 이번만은 정파 떠나 '국민 安全' 머리 맞대야[사설] 無能한...   \n",
       "18  2014.06  [사설] 金 안보실장, '또 軍 출신 발탁'에 대한 우려 씻어내야[사설] 완승·완패...   \n",
       "19  2014.07  [사설] 대통령의 '총리 留任' 해명, 이 정도로 충분하겠나[사설] 해직 교사 9명...   \n",
       "20  2014.08  [사설] 시대 변화 못 읽는 野, 이대로는 미래 없다[사설] 美·유엔, 위안부 문제...   \n",
       "21  2014.09  [사설] 최전방 사령관의 軍律 무시·만취 추태, 어쩌다 이 지경 됐나[사설] 규제 ...   \n",
       "22  2014.10  [사설] 北 실세들의 깜짝 방문, 차분하게 남북대화 이끌어야[사설] 군·국정원 人事...   \n",
       "23  2014.11  [사설] 애당초 海警·소방청 해체 발표가 성급했다[사설] 세월號특별법 합의, 이젠 ...   \n",
       "24  2014.12  [사설] 박 대통령, '정윤회 文件' 유출만 탓할 일 아니다[사설] '1兆 배당說'...   \n",
       "25  2015.01  [사설] 분단 70년 恨 푸는 남북 정상회담을 바란다[사설] 檢 \"정윤회 문건은 허...   \n",
       "26  2015.02  [사설] 非朴 원내대표 당선은 대통령 향한 여당의 경고[사설] '국민 속였다'는 與...   \n",
       "27  2015.03  [사설] 현역 의원 대통령 보좌관 임명은 3權분립 위반 아닌가[사설] 한국이 처음 ...   \n",
       "28  2015.04  [사설] 대통령이 제주 4·3 추념식에 참석할 수 있으려면[사설] '세월호 인양 결...   \n",
       "29  2015.05  [사설] 외교도, 경제도,개혁도 못하는 '무기력 청와대'[사설] 朴 대통령, '정치...   \n",
       "30  2015.06  [사설] 전면전으로 번지는 黨·靑 '국회법' 갈등, 국민은 안중에도 없나[사설] 野...   \n",
       "31  2015.07  [사설] 국회법 再議 뭉개겠다는 與, 이게 올바른 집권당 자세인가[사설] 경제는 6...   \n",
       "32  2015.08  [사설] 極端에서 극단으로 오가는 對日 외교[사설] 정 내정자, '의료계 대변인' ...   \n",
       "33  2015.09  [사설] 박 대통령 訪中, '美 의구심' 씻어낼 외교 전략 절실하다[사설] 밖의 시...   \n",
       "34  2015.10  [사설] 박 대통령과 김 대표, 공천권 놓고 벌써 공개 舌戰 벌일 때인가[사설] 靑...   \n",
       "35  2015.11  [사설] 韓·日 정상, '新조선통신사의 和合 염원' 외면 말라[사설] 韓中日 3자회...   \n",
       "36  2015.12  [사설] 박 대통령, 野·노조 지도자 만나 간절하게 호소해보라[사설] 막장 집안싸움...   \n",
       "37  2016.01  [사설] 새로운 政治 리더십으로 나라가 활기 되찾아야 한다[사설] 잘나가는 벤처 강...   \n",
       "38  2016.02  [사설] 제4이동통신 또 무산, 미래창조부 제대로 하는 일 뭐 있나[사설] 알맹이 ...   \n",
       "39  2016.03  [사설] 쪼그라드는 경제, '好況 맛' 한번 못 보고 5년 임기 끝낼 건가[사설] ...   \n",
       "40  2016.04  [사설] 한·미·일 공조 강화해 中의 '북한 압박' 약속 지키게 해야[사설] 시진핑...   \n",
       "41  2016.05  [사설] 새 차원의 中東 大전략 나와야 할 때다[사설] 北은 우방국 이란 대통령의 ...   \n",
       "42  2016.06  [사설] 20대 국회 개혁 '불체포特權 폐지' 하나에 달렸다[사설] 줄거리조차 못 ...   \n",
       "43  2016.07  [사설] 한국형 우주로켓 연기, 무리한 대선 公約에 무너진 '과학'[사설] 조응천 ...   \n",
       "44  2016.08  [사설] 근로자 절반이 소득세 '0', 정치 포퓰리즘 결과[사설] \"禹 수석 정상 ...   \n",
       "45  2016.09  [사설] 방어 무기 하나 놓고 두 달 소란, 政局 마비된 나라[사설] 나라 사방이 ...   \n",
       "46  2016.10  [사설] 미르·K스포츠 재단 뒤늦게 해산·통합한다는데[사설] 상식으로 납득하기 어려...   \n",
       "47  2016.11  [사설] 최순실 출두 이어 대통령이 고백하길[사설] 박 대통령 脫黨하고 친박·비박 ...   \n",
       "48  2016.12  [사설] '親朴 개헌' 불가능, 朴 대통령은 퇴진 명확히 하길[사설] 野 대통령 퇴...   \n",
       "49  2017.01  [사설] \"엮지 말라\" 전면 부인 나선 朴 대통령[사설] 탄핵 반대 고교생이 당한 ...   \n",
       "50  2017.02  [사설] 최순실, 장차관·수석 이어 大使 임명도 개입했다니[사설] 國定교과서와 質로...   \n",
       "51  2017.03  [사설] 역사적 탄핵 심판 첫 평의, '절대 非공개'로 헌재 보호해야[사설] 촛불·...   \n",
       "52  : 2016.  [사설] 알맹이 빠지는 노동 개혁, 이러려면 뭐하러 그 요란 떨었나[사설] 원칙도 ...   \n",
       "\n",
       "                                                 body  \n",
       "0   19일 실시된 대통령선거에서 새누리당 박근혜 후보가 투표자 3072만명 중 51% ...  \n",
       "1   김정은 북한 노동당 제1비서는 1일 북한 매체를 통해 중계된 육성 신년사에서 \"나라...  \n",
       "2   박근혜 대통령 당선인은 1월 31일 인사청문회에 대해 \"공직자의 신상에 대한 문제는...  \n",
       "3   새누리당 황우여 대표와 이한구 원내대표는 2월 28일 최고위원 회의 모두 발언에서 ...  \n",
       "4   정부가 올해 예산 편성을 하면서 교통범칙금 징수 목표 액수를 작년보다 12%(900...  \n",
       "5   정부는 1일 열린 무역투자진흥회의에서 그동안 허가를 미루고 있던 에쓰오일·SK종합화...  \n",
       "6   4일 박근혜 대통령은 취임 100일을 맞는다. 취임 100일을 앞두고 미디어리서치가...  \n",
       "7   박근혜 대통령이 4일간의 중국 방문을 마치고 30일 귀국했다. 박 대통령은 새 대통...  \n",
       "8   여야는 4일 국정원 국정조사 정상화 협상을 재개, 국정원 보고를 예정대로 듣기로 하...  \n",
       "9   정기국회가 2일 문을 열었지만 여야는 통합진보당 이석기 의원 체포동의안 처리에 합의...  \n",
       "10  박근혜 대통령은 30일 청와대 수석비서관 회의에서 \"기초연금 정부안(案)에 대해 청...  \n",
       "11  민주당이 30일 경기 화성갑과 경북 포항남·울릉 등 두 곳에서 실시된 국회의원 보선...  \n",
       "12  우태희 산업통상자원부 통상교섭실장은 \"우리가 12개 태평양 연안국이 추진하고 있는 ...  \n",
       "13  국무총리 산하 1급 실장급 공무원 10명 전원이 최근 사직서를 냈다고 한다. 집단 ...  \n",
       "14  오는 4월로 예정된 오바마 미국 대통령의 아시아 순방 일정을 놓고 한국과 일본이 외...  \n",
       "15  3일 서울에서 열린 조선일보 주최 제5회 아시안리더십콘퍼런스의 주제는 '하나의 한국...  \n",
       "16  북한이 31일 낮 서해 북방한계선(NLL) 인근 해역에서 대규모 사격 훈련을 실시했...  \n",
       "17  박근혜 대통령은 그제 국무회의에서 \"과거로부터 쌓여온 잘못된 적폐(積弊)를 바로잡지...  \n",
       "18  박근혜 대통령은 1일 신임 청와대 국가안보실장에 김관진 현 국방장관을 임명하고, 후...  \n",
       "19  박근혜 대통령이 30일 청와대 수석비서관 회의에서 정홍원 총리를 유임시킨 이유에 대...  \n",
       "20  새정치민주연합 지도부가 31일 총사퇴했다. 새정치연합은 전날 전국 15곳에서 치러진...  \n",
       "21  신현돈 육군 1군 사령관(대장)이 2일 갑작스럽게 전역(轉役) 조치됐다. 현역 군인...  \n",
       "22  남북 관계가 뜻밖의 전기(轉機)를 맞았다. 북한 권력 서열 2위로 평가되는 황병서 ...  \n",
       "23  여야는 31일 소방방재청과 해양경찰청을 해체한 뒤 새로 생기는 국민안전처 산하 '중...  \n",
       "24  박근혜 대통령이 1일 청와대 회의에서 '정윤회 국정 개입 의혹 문서' 유출 사건에 ...  \n",
       "25  북한 김정은 노동당 제1비서는 1일 TV에 나와 직접 발표한 신년사를 통해 \"올해 ...  \n",
       "26  2일 실시된 새누리당 원내대표 경선에서 유승민 의원이 84표를 얻어 65표에 그친 ...  \n",
       "27  청와대는 지난주 새누리당 주호영·윤상현·김재원 의원을 대통령 정무특보로 임명하면서 ...  \n",
       "28  오늘 제주도 4·3 평화공원에서 지난해 3월 국가 기념일로 지정된 '4·3 희생자 ...  \n",
       "29  박근혜 대통령이 조만간 공식 일정을 재개할 예정이라 한다. 지난 보름여 동안 이 정...  \n",
       "30  박근혜 대통령이 1일 여야 합의로 국회를 통과한 국회법 개정안에 대해 \"정부로서는 ...  \n",
       "31  정의화 국회의장은 30일 박근혜 대통령이 거부권을 행사한 '국회법 개정안'을 국회 ...  \n",
       "32  박근혜 대통령이 3일 일본 야당인 민주당의 오카다 가쓰야 대표를 만난 자리에서 \"과...  \n",
       "33  윤병세 외교부장관이 31일(현지 시각) 미국 알래스카주(州) 앵커리지에서 존 케리 ...  \n",
       "34  청와대 고위 관계자가 30일 김무성 새누리당·문재인 새정치연합 대표가 내년 총선 공...  \n",
       "35  화합의 꿈을 안고 달린 50명의 한·일 자전거 라이더 '두 바퀴로 달리는 신(新)조...  \n",
       "36  박근혜 대통령은 7일 김무성 대표, 원유철 원내대표 등 여당 지도부를 만나 \"지금 ...  \n",
       "37  1492년 콜럼버스가 배 세 척을 이끌고 신대륙에 도달했을 당시 유럽인은 중국을 이...  \n",
       "38  제4이동통신 사업자 선정이 또다시 무산됐다. 이 사업은 SK, LG, KT 등 대기...  \n",
       "39  지난해 우리나라의 1인당 국민소득이 2만7200달러를 기록, 9년째 3만달러 문턱을...  \n",
       "40  제4차 핵안보정상회의에 앞서 31일 미국 워싱턴DC에서 열린 한·미·일 정상회의에서...  \n",
       "41  박근혜 대통령이 1일 이란을 방문했다. 한국 대통령으로는 1962년 국교 수교 이후...  \n",
       "42  원혜영 더불어민주당 의원이 31일 '국회의원 불체포특권 남용 방지법'을 제출했다. ...  \n",
       "43  국산 우주로켓을 개발 중인 한국항공우주연구원이 당초 내년 12월로 예정했던 한국형 ...  \n",
       "44  국책 연구기관인 조세재정연구원이 우리나라 근로자 가운데 세금을 한 푼도 내지 않는 ...  \n",
       "45  사드(고고도 미사일 방어 체계)가 연이틀 국회를 마비시켰다. 여당이 정치 중립 위반...  \n",
       "46  전경련은 30일 사실상 청와대가 설립했다는 의혹이 제기된 미르(용·龍)와 K스포츠 ...  \n",
       "47  최순실씨가 31일 검찰에 출석했다. 최씨는 \"국민 여러분, 용서해주십시오\"라고 했다...  \n",
       "48  박근혜 대통령이 지난 29일 자신의 임기 단축 문제를 국회에 일임하겠다고 밝혔지만 ...  \n",
       "49  직무 정지 중인 박근혜 대통령이 1일 기자들과 신년인사회 자리에서 특검의 '삼성 합...  \n",
       "50  최순실씨가 유재경 주(駐)미얀마 대사 임명 및 해외 공적개발원조(ODA) 사업에도 ...  \n",
       "51  헌법재판소가 28일 재판관 8명 전원이 참석한 가운데 박근혜 대통령 탄핵심판 첫 평...  \n",
       "52  정부와 새누리당이 국회 쟁점 법안 중 하나인 파견근로자보호법 개정안에서 뿌리 산업의...  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dates in month:\n",
    "\n",
    "    # data revise에서 샘플링\n",
    "    sample = data_revise[data_revise.date == dates]\n",
    "\n",
    "    titles = sample.title.values\n",
    "    titles = list(titles)\n",
    "    titles = ''.join(titles)\n",
    "    \n",
    "    articles = sample.body.values\n",
    "    articles = list(articles)\n",
    "    articles = ''.join(articles)\n",
    "\n",
    "    data = {\n",
    "        \"date\" : dates,\n",
    "        \"title\" : titles,\n",
    "        \"body\" : articles\n",
    "    }\n",
    "    \n",
    "    data_merged.loc[len(data_merged)] = data\n",
    "\n",
    "data_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.to_pickle('cs_data_merged_v1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 \n",
      " <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "corpus = data_merged.body.values\n",
    "corpus = list(corpus)\n",
    "\n",
    "print(len(corpus), \"\\n\", type(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.tokenizer import LTokenizer, MaxScoreTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def make_dataset(corpus):\n",
    "\n",
    "    # scores dict로 cohesion scores, ltokenizer 만들기\n",
    "    cohesion_scores = {word:score.cohesion_forward for word, score in scores.items()}\n",
    "    ltokenizer = LTokenizer(scores=cohesion_scores)\n",
    "\n",
    "    def l_tokenizer(word):\n",
    "        return ltokenizer.tokenize(word, remove_r=True)\n",
    "\n",
    "    # ltokenizer를 활용해서 벡터라이저 만들기\n",
    "    vectorizer = CountVectorizer(\n",
    "        tokenizer=l_tokenizer,\n",
    "    )\n",
    "\n",
    "    # x 만들기\n",
    "    x = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    # vocab2int, int2vocab 만들기\n",
    "    vocab2int = vectorizer.vocabulary_\n",
    "    int2vocab = [\n",
    "        word for word, index in sorted(vocab2int.items(), key=lambda x:x[1])\n",
    "    ]\n",
    "    \n",
    "    return x, vocab2int, int2vocab\n",
    "\n",
    "x, vocab2int, int2vocab = make_dataset(corpus)\n",
    "\n",
    "def word2int(word):\n",
    "    return vocab2int.get(word, -1)\n",
    "\n",
    "def int2word(idx):\n",
    "    if 0 <= idx < len(int2vocab):\n",
    "        return int2vocab[idx]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x train, y train 으로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(word):\n",
    "    \n",
    "    word_idx = word2int(word) # word2int 함수 필요\n",
    "    positive_document = x[:, word_idx].nonzero()[0] # x 데이터셋 필요\n",
    "    \n",
    "    def get_label(i):\n",
    "        return 1 if i in positive_document else -1\n",
    "    \n",
    "    y_train = [get_label(i) for i in range(x.shape[0])]\n",
    "    \n",
    "    (row, col) = x.nonzero()\n",
    "    data = x.data\n",
    "    \n",
    "    row_ = []\n",
    "    col_ = []\n",
    "    data_ = []\n",
    "    \n",
    "    for r, c, d in zip(row, col, data):\n",
    "        if c == word_idx:\n",
    "            continue\n",
    "        row_.append(r)\n",
    "        col_.append(c)\n",
    "        data_.append(d)\n",
    "        \n",
    "    from scipy.sparse import csr_matrix\n",
    "    x_train = csr_matrix((data_, (row_, col_)))\n",
    "    \n",
    "    return x_train, y_train\n",
    "\n",
    "x_train, y_train = get_train_data('박근혜')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유사어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-276-da323979af53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogistic_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlogistic_l1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    870\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[1;32m    871\u001b[0m                              \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mclass_weight_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_l1 = LogisticRegression(penalty='l1', C=10)\n",
    "logistic_l1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-277-eff592d08a92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogistic_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlogistic_l1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlasso_keyword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    870\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[1;32m    871\u001b[0m                              \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mclass_weight_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_l1 = LogisticRegression(penalty='l1', C=10)\n",
    "logistic_l1.fit(x_train, y_train)\n",
    "\n",
    "def lasso_keyword(word, C=20, topk=20):\n",
    "    if not (word in vocab2int):\n",
    "        return []\n",
    "    \n",
    "    x_train, y_train = get_train_data(word)\n",
    "    logistic_l1 = LogisticRegression(penalty='l1', C=C)\n",
    "    logistic_l1.fit(x_train, y_train)\n",
    "    \n",
    "    idx_coef = enumerate(logistic_l1.coef_.reshape(-1))\n",
    "    sorted_coefficients = sorted(idx_coef, key=lambda x:-x[1])\n",
    "    \n",
    "    # filtering keyword\n",
    "    keywords = [word_idx for word_idx, coef in sorted_coefficients[:topk] \n",
    "                if coef > 0.001]\n",
    "    \n",
    "    # decode idx to str\n",
    "    keywords = [int2word(word_idx) for word_idx in keywords]\n",
    "    return keywords\n",
    "\n",
    "print(lasso_keyword('박근혜'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 노트\n",
    "\n",
    "- 유사어는 특정 키워드를 동일하게 가지고 있는 문서 안에 있는 키워드를 유사어로 지정한다. \n",
    "> 그러므로 차라리 월 별 코퍼스의 키워드를 분석하는 게 더 나을 것 같다.\n",
    "\n",
    "- 대부분 \"박근혜\" 키워드를 가지고 있으므로, 연관어 / 키워드를 분류하는게 애초에 불가능하다. Lasso를 사용하는 경우는, logistic regression은 대표벡터를 학습해야 하는데 위 코퍼스는 전부 다 \"박근혜\"라는 단어를 포함하고 있어, 2개 이상 집단으로 나뉘지 않아 2개 이상의 대표벡터가 존재하지 않기 때문이다.\n",
    "> 그렇다면 \"박근혜\"를 코퍼스에서 제거한 후 연관어, 키워드를 분석하면 어떨까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 키워드 추출(선회)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x3101 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3101 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixbasedKeywordExtractor trained\n"
     ]
    }
   ],
   "source": [
    "from soykeyword.proportion import MatrixbasedKeywordExtractor\n",
    "\n",
    "proportion_based_extractor = MatrixbasedKeywordExtractor(\n",
    "    min_tf=0, \n",
    "    min_df=0,\n",
    "    verbose=True)\n",
    "\n",
    "proportion_based_extractor.train(x, int2vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-272-3dc3b3e99f04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproportion_based_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_from_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'박근혜'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/soykeyword/proportion/_proportion.py\u001b[0m in \u001b[0;36mextract_from_word\u001b[0;34m(self, word, min_frequency, min_score)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpos_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_from_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_frequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_document_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/soykeyword/proportion/_proportion.py\u001b[0m in \u001b[0;36mextract_from_docs\u001b[0;34m(self, docs, min_frequency, min_score)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_negative_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sum_to_proportion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mnp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sum_to_proportion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/soykeyword/proportion/_proportion.py\u001b[0m in \u001b[0;36m_sum_to_proportion\u001b[0;34m(self, sum_dict)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sum_to_proportion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0msum_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msum_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_positive_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/soykeyword/proportion/_proportion.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sum_to_proportion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0msum_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msum_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_positive_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "keywords = proportion_based_extractor.extract_from_word('박근혜')\n",
    "keywords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 노트\n",
    "\n",
    "- \"박근혜\"가 포함된 문서의 키워드를 추출하려니, 확률 기반 추출방법도 제대로 되지 않는다. \n",
    "> 우선 가장 간단한 방법인 워드 클라우드부터 시도해봐야겠다. 월 별 가장 높은 빈도가 나오는 명사, 용언만 추출해서 보여주도록."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
